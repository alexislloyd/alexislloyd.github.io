<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"
   "http://www.w3.org/TR/html4/strict.dtd">

<html lang="en">
<head>
	<script type="text/javascript">var _sf_startpt=(new Date()).getTime()</script>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="viewport" content="width=device-width">
	<title>Alexis Lloyd: Projects</title>

	<!--styles-->
	<link rel="stylesheet" href="projects.css" type="text/css" media="screen" charset="utf-8">
	<link rel="stylesheet" href="../reset.css" type="text/css" media="screen" charset="utf-8">
<link href='https://fonts.googleapis.com/css?family=Montserrat:400,700|Neuton:400,300,400italic' rel='stylesheet' type='text/css'>
	<link href='https://fonts.googleapis.com/css?family=Inconsolata:400,700' rel='stylesheet' type='text/css'>

	


</head>
<body>
	<div id="wrapper">

		<div id="header">
			<p><a href="http://www.alexislloyd.com">Alexis Lloyd</a></p>
			<!--<div id="subhed">DESIGN &bull; FUTURES &bull; RESEARCH &bull; CODE</div>-->
		</div>

		<!--mission-->
		<div id="project-title">
			Object Record (2014)
		</div>

		<!--projects-->
		<div id="project-info">
			<div class="main-img">
				<img src="../images/objectrecord-big.jpg" />
			</div>

<p class="role">ROLE: Concept, Interaction design, Development of language generation software.<br />
COLLABORATORS: Noah Feehan, Matt Boggie</p>

<p>Object Record explores everyday objects’ relationships to different environmental conditions and their subjective responses to changes in those conditions. A set of three objects are presented, each paired with a sensor. Visitors can manipulate the sensor readings through touch, motion, etc. In response to changing input, the object will print out a continual monologue of its perceptions of and responses to that data. The text of the monologue is printed out in ticker form on a mini printer so that visitors can see not only the current state of the object, but also peruse the paper trail of the object’s memory.</p>

<p>Object Record was created for the gallery at the Future of Storytelling conference and is part of a series of works exploring the the narrative possibilities embedded in the Internet of Things. As more of our objects and environments become actuated, connected, and data-enabled, these enchanted objects are developing the capacity to contain their own stories. An object can remember its history, can understand how it is used, can talk to other objects around it to understand its environment. As these capabilities evolve, objects no longer become inert backdrops to our experiences, but active participants in our world that can share stories about themselves and us. Other work on this topic includes <a href="http://futureofstorytelling.org/video/object-narratives/">a short film entitled Object Narratives</a> and an article I wrote for The Atlantic entitled "<a href="http://www.theatlantic.com/technology/archive/2013/09/if-this-toaster-could-talk/279276/">If This Toaster Could Talk: Narrative in the Age of the Smart Object</a>".<!--more--></p>



		</div>

		

	</div><!--end wrapper-->




</body>
</html>
